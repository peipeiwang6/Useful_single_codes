{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'D:\\Evans microbial community\\data_for_pipeline\\metadata_full_MMPRNT_G5.LC_LUX_trunc_rar_016017_v2.txt'\n",
    "#label = 'D:\\Evans microbial community\\data_for_pipeline\\ELSA_module_016017_LUX_OTU_sum_MMPRNT_G5_LC_LUX_016017.txt'\n",
    "label = 'D:\\Evans microbial community\\data_for_pipeline\\Rarefied_diversity_MMPRNT_G5_LC_LUX_016017.txt'\n",
    "site = 'LUX'\n",
    "site_not_used = 'LC'\n",
    "cv_num = 10\n",
    "test_size = 0.1 ### what the proportion of your data you want to hold out as test set, \n",
    "                ### which will never be seen when you train the model\n",
    "feature_2_onehotencoding = ['FertStatus','thermal_two_year','thermal_2019','thermal_2018']\n",
    "ML_method = 'RandomForestRegressor'\n",
    "short_name = 'Multioutput_regression_richness_randomized'\n",
    "save_model = '%s_%s.sav'%(short_name,ML_method)\n",
    "save_parameter = '%s_%s_parameter.txt'%(short_name,ML_method)\n",
    "save_performance = '%s_%s_performance.txt'%(short_name,ML_method)\n",
    "save_imp = '%s_%s_feature_importance.txt'%(short_name,ML_method)\n",
    "randomized = 'True' # or 'False'. Note that if randomized = 'True', don't forget to change the short_name, in case your previous results would be overwrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, sep='\\t', index_col = 0, header = 0)\n",
    "if 'ELSA' in label:\n",
    "    df_lable = pd.read_csv(label, sep='\\t', index_col = 42, header = 0)\n",
    "if 'Rarefied' in label:\n",
    "    df_lable = pd.read_csv(label, sep='\\t', index_col = 0, header = 0)\n",
    "ML_matrix = pd.concat([df_lable,df], axis=1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_site = ML_matrix.loc[ML_matrix['siteID']==site]\n",
    "df_target_site = df_target_site.drop([\"collectionDate\",\"siteID\",\\\n",
    "                                             \"UTM_Lat_Cord\",\"UTM_Lon_Cord\"],axis=1)\n",
    "\n",
    "df_other_site = ML_matrix.loc[ML_matrix['siteID']==site_not_used]\n",
    "df_other_site = df_other_site.drop([\"collectionDate\",\"siteID\",\\\n",
    "                                             \"UTM_Lat_Cord\",\"UTM_Lon_Cord\"],axis=1)\n",
    "\n",
    "df_target_site[\"thermal_two_year\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data to traning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df_target_site, \\\n",
    "                                       test_size=test_size, random_state=42)\n",
    "X_train = train_set.drop(df_lable.columns, axis=1) \n",
    "X_test = test_set.drop(df_lable.columns, axis=1)\n",
    "X_on_test_site = df_other_site.drop(df_lable.columns, axis=1)\n",
    "\n",
    "y_train = train_set[df_lable.columns]\n",
    "y_test = test_set[df_lable.columns]\n",
    "y_on_test_site = df_other_site[df_lable.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding, handle with NaN data (keep them as NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def OneHotEncoder_fit_transform(df,feature_2_onehotencoding):\n",
    "    new_columns = []\n",
    "    Onehot = {}\n",
    "    col_2_1hot = df.loc[:,feature_2_onehotencoding]\n",
    "    for col in feature_2_onehotencoding:\n",
    "        Onehot[col] = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        c_1hot_use = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].notna(),col])\n",
    "        c_1hot_na = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].isna(),col])\n",
    "        if c_1hot_na.shape[0] == 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].fit_transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = col_2_1hot.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                new_columns.append(columns)\n",
    "        if c_1hot_na.shape[0] != 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].fit_transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = c_1hot_use.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                c_1hot_na[columns] = np.nan\n",
    "                new_columns.append(columns)\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)\n",
    "            c_1hot_encoded = pd.concat([c_1hot_encoded,c_1hot_na],axis=0)\n",
    "        df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "    return(df,Onehot,new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder_transform(df,feature_2_onehotencoding,Onehot):\n",
    "    col_2_1hot = df.loc[:,feature_2_onehotencoding]\n",
    "    for col in feature_2_onehotencoding:\n",
    "        c_1hot_use = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].notna(),col])\n",
    "        c_1hot_na = pd.DataFrame(col_2_1hot.loc[col_2_1hot.loc[:,col].isna(),col])\n",
    "        if c_1hot_na.shape[0] == 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = col_2_1hot.index\n",
    "            df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "        if c_1hot_na.shape[0] != 0 and c_1hot_use.shape[0] != 0:\n",
    "            c_1hot_encoded = pd.DataFrame(Onehot[col].transform(c_1hot_use))\n",
    "            c_1hot_encoded.columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            c_1hot_encoded.index = c_1hot_use.index\n",
    "            for columns in c_1hot_encoded.columns:\n",
    "                c_1hot_na[columns] = np.nan\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)\n",
    "            c_1hot_encoded = pd.concat([c_1hot_encoded,c_1hot_na],axis=0)\n",
    "            df = pd.concat([df,c_1hot_encoded],axis=1)\n",
    "        if c_1hot_use.shape[0] == 0:\n",
    "            columns = [col + '_' + '%s'%sub for sub in Onehot[col].categories_[0]]\n",
    "            for column in columns:\n",
    "                c_1hot_na[column] = np.nan\n",
    "            c_1hot_na = c_1hot_na.drop(col,axis=1)  \n",
    "            df = pd.concat([df,c_1hot_na],axis=1)\n",
    "    return(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "D:\\softinstall\\Anaconda3\\envs\\tf2\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Onehot, new_columns = OneHotEncoder_fit_transform(X_train,feature_2_onehotencoding)\n",
    "X_test = OneHotEncoder_transform(X_test,feature_2_onehotencoding,Onehot)\n",
    "X_on_test_site = OneHotEncoder_transform(X_on_test_site,feature_2_onehotencoding,Onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(feature_2_onehotencoding,axis=1)\n",
    "X_test = X_test.drop(feature_2_onehotencoding,axis=1)\n",
    "X_on_test_site = X_on_test_site.drop(feature_2_onehotencoding,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing data using KNN, five Ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. drop features with >50% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miss_count = X_train.count(0)\n",
    "Col_to_drop = Miss_count[Miss_count <= 0.5*X_train.shape[0]].index.tolist()\n",
    "Col_to_drop\n",
    "X_train.drop(Col_to_drop,axis=1,inplace=True)\n",
    "X_test.drop(Col_to_drop,axis=1,inplace=True)\n",
    "X_on_test_site.drop(Col_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "class KNNImputer_Ks(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, *Ks):\n",
    "        self.Ks = Ks\n",
    "    def fit(self, X,Ks):\n",
    "        D_imputer = {}        \n",
    "        for k in [3,4,5,6,7]:\n",
    "            imputer = KNNImputer(n_neighbors=k)\n",
    "            D_imputer[k] = imputer.fit(X)              \n",
    "        return D_imputer\n",
    "    def transform(self, X):\n",
    "        Impute_train = {}\n",
    "        for k in [3,4,5,6,7]:\n",
    "            Impute_train[k] = pd.DataFrame(D_imputer[k].transform(X))\n",
    "            Impute_train[k].index = X.index\n",
    "            Impute_train[k].columns = X.columns \n",
    "            if k == 3:\n",
    "                Imputed = Impute_train[k].copy(deep=True)\n",
    "                Imputed.loc[:,:] = 0\n",
    "            Imputed = Imputed.add(Impute_train[k],fill_value=0)\n",
    "        return Imputed/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_knn = KNNImputer_Ks()\n",
    "D_imputer = imputer_knn.fit(X_train, Ks=\"3,4,5,6,7\")\n",
    "X_train_KNN = imputer_knn.transform(X_train)\n",
    "X_test_KNN = imputer_knn.transform(X_test)\n",
    "X_on_test_site_KNN =  imputer_knn.transform(X_on_test_site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### round the imputed values for binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_columns:\n",
    "    X_train_KNN[col] = round(X_train_KNN[col],0)\n",
    "    X_test_KNN[col] = round(X_test_KNN[col],0)\n",
    "    X_on_test_site_KNN[col] = round(X_on_test_site_KNN[col],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the y_train, y_test to get the backgound, or performance of random guessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from numpy.random import permutation\n",
    "if randomized == 'True':\n",
    "    for i in range(0,y_train.shape[1]):\n",
    "        y_train.iloc[:,i] = np.random.permutation(y_train.iloc[:,i])\n",
    "        y_test.iloc[:,i] = np.random.permutation(y_test.iloc[:,i])\n",
    "        y_on_test_site.iloc[:,i] = np.random.permutation(y_on_test_site.iloc[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.shape[1] == 1:\n",
    "    param_grid = {'max_depth':[3, 5, 10], \\\n",
    "              'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "              'n_estimators': [10, 100,500,1000]}\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=cv_num, \\\n",
    "                           scoring='neg_mean_squared_error', verbose=2,n_jobs=5)\n",
    "    grid_search.fit(X_train_KNN, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=5)]: Done 600 out of 600 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  1.8min\n"
     ]
    }
   ],
   "source": [
    "if y_train.shape[1] > 1:    \n",
    "    gsc = GridSearchCV(\n",
    "                estimator=RandomForestRegressor(random_state=42),\n",
    "                param_grid={'max_depth':[3, 5, 10], \\\n",
    "                  'max_features': [0.1, 0.5, 'sqrt', 'log2', None], \\\n",
    "                  'n_estimators': [10, 100,500,1000]},    \n",
    "                cv=cv_num, scoring='neg_mean_squared_error', verbose=2, n_jobs=5)\n",
    "    grid_search = MultiOutputRegressor(gsc).fit(X_train_KNN, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCC_multioutput(y,pred):\n",
    "    R = []\n",
    "    for i in range(0,y.shape[1]):\n",
    "        R.append(np.corrcoef(np.array(y.iloc[:,i]), np.array(pred.iloc[:,i]))[0,1])\n",
    "                 \n",
    "    return (np.array(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # mse: Mean squared error regression loss\n",
    "    # evs: Explained variance regression score\n",
    "    # r2: (coefficient of determination) regression score. Best possible score is 1.0 and it can \n",
    "    be negative (because the model can be arbitrarily worse). A constant model that always \n",
    "    predicts the expected value of y, \n",
    "    # disregarding the input features, would get a R^2 score of 0.0.\n",
    "    # cor: Pearson Correlation Coefficient between true y and predicted y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.shape[1] == 1:\n",
    "    cv_pred = cross_val_predict(estimator=grid_search.best_estimator_, X=X_train_KNN, \\\n",
    "                                y=y_train, cv=cv_num)\n",
    "    cv_mse = mean_squared_error(y_train, cv_pred)\n",
    "    cv_evs = explained_variance_score(y_train, cv_pred)\n",
    "    cv_r2 = r2_score(y_train, cv_pred)\n",
    "    cv_cor = np.corrcoef(np.array(y_train), cv_pred)[0,1]\n",
    "    \n",
    "    pred_train = grid_search.best_estimator_.predict(X_train_KNN)\n",
    "    train_mse = mean_squared_error(y_train, pred_train)\n",
    "    train_evs = explained_variance_score(y_train, pred_train)\n",
    "    train_r2 = r2_score(y_train, pred_train)\n",
    "    train_cor = np.corrcoef(np.array(y_train), pred_train)[0,1]\n",
    "    \n",
    "    pred_test = grid_search.best_estimator_.predict(X_test_KNN)\n",
    "    test_mse = mean_squared_error(y_test, pred_test)\n",
    "    test_evs = explained_variance_score(y_test, pred_test)\n",
    "    test_r2 = r2_score(y_test, pred_test)\n",
    "    test_cor = np.corrcoef(np.array(y_test), pred_test)  \n",
    " \n",
    "    pred_test = grid_search.best_estimator_.predict(X_on_test_site_KNN)\n",
    "    test_site_mse = mean_squared_error(y_on_test_site, pred_on_test_site)\n",
    "    test_site_evs = explained_variance_score(y_on_test_site, pred_on_test_site)\n",
    "    test_site_r2 = r2_score(y_on_test_site, pred_on_test_site)\n",
    "    test_site_cor = np.corrcoef(np.array(y_on_test_site), pred_on_test_site)[0,1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mul_reg_cv_predict(Mul_estimators,X,y):\n",
    "    pred = pd.DataFrame()\n",
    "    for i in range(0,y.shape[1]):\n",
    "        prediction = pd.DataFrame(cross_val_predict(estimator=Mul_estimators.estimators_[i].best_estimator_, \\\n",
    "                                              X=X, y=y.iloc[:,i], cv=cv_num))\n",
    "        pred = pd.concat([pred,prediction],axis=1)\n",
    "    pred.columns = y.columns\n",
    "    pred.index = y.index\n",
    "    return (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mul_reg_predict(Mul_estimators,X,y):\n",
    "    pred = pd.DataFrame()\n",
    "    for i in range(0,y.shape[1]):\n",
    "        prediction = pd.DataFrame(Mul_estimators.estimators_[i].best_estimator_.predict(X))\n",
    "        pred = pd.concat([pred,prediction],axis=1)\n",
    "    pred.columns = y.columns\n",
    "    pred.index = y.index\n",
    "    return (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.shape[1] > 1:\n",
    "    cv_pred = Mul_reg_cv_predict(grid_search, X_train_KNN, y_train)\n",
    "    cv_mse = mean_squared_error(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_evs = explained_variance_score(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_r2 = r2_score(y_train, cv_pred,multioutput='raw_values')\n",
    "    cv_cor = PCC_multioutput(y_train, cv_pred)\n",
    "    \n",
    "    pred_train = Mul_reg_predict(grid_search, X_train_KNN, y_train)\n",
    "    train_mse = mean_squared_error(y_train, pred_train,multioutput='raw_values')\n",
    "    train_evs = explained_variance_score(y_train, pred_train,multioutput='raw_values')\n",
    "    train_r2 = r2_score(y_train, pred_train,multioutput='raw_values')\n",
    "    train_cor = PCC_multioutput(y_train, pred_train)    \n",
    "    \n",
    "     \n",
    "    pred_test = Mul_reg_predict(grid_search, X_test_KNN, y_test)\n",
    "    test_mse = mean_squared_error(y_test, pred_test,multioutput='raw_values')\n",
    "    test_evs = explained_variance_score(y_test, pred_test,multioutput='raw_values')\n",
    "    test_r2 = r2_score(y_test, pred_test,multioutput='raw_values')\n",
    "    test_cor = PCC_multioutput(y_test, pred_test) \n",
    "    \n",
    "    pred_on_test_site = Mul_reg_predict(grid_search, X_on_test_site_KNN, y_on_test_site)\n",
    "    test_site_mse = mean_squared_error(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_evs = explained_variance_score(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_r2 = r2_score(y_on_test_site, pred_on_test_site,multioutput='raw_values')\n",
    "    test_site_cor = PCC_multioutput(y_on_test_site, pred_on_test_site)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if y_train.shape[1] == 1:\n",
    "    pickle.dump(grid_search.best_estimator_, open(save_model, 'wb'))\n",
    "else:\n",
    "    pickle.dump(grid_search, open(save_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(save_parameter,'w')\n",
    "out.write('The model is built using data from %s, and applied to %s and %s.\\n\\n'%(site,site,site_not_used))\n",
    "out.write('There are %s training instances.\\n'%X_train_KNN.shape[0])\n",
    "out.write('There are %s test instances.\\n'%X_test_KNN.shape[0])\n",
    "out.write('There are %s instances in the other site.\\n'%X_on_test_site_KNN.shape[0])\n",
    "out.write('There are %s feature used\\n\\n'%X_train_KNN.shape[1])\n",
    "if y_train.shape[1] == 1:\n",
    "    out.write('The model is built using %s, with:\\n'%ML_method)\n",
    "    for key in grid_search.best_params_:\n",
    "        out.write('\\t%s: %s\\n'%(key,grid_search.best_params_[key]))\n",
    "\n",
    "if y_train.shape[1] > 1:\n",
    "    out.write('The model is built using %s, multioutput, with:\\n'%ML_method)\n",
    "    for i in range(0, y_train.shape[1]):\n",
    "        g = grid_search.estimators_[i].best_params_\n",
    "        out.write('\\t\\t%s:\\n'%y_train.columns[i])\n",
    "        for key in g:\n",
    "            out.write('\\t\\t\\t%s: %s\\n'%(key,g[key]))\n",
    "            \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write performance of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.shape[1] == 1:\n",
    "    out = open(save_performance,'w')\n",
    "    out.write('Prediction\\tmse\\tevs\\tr2\\tPCC\\n')\n",
    "    out.write('CV\\t%s\\t%s\\t%s\\t%s\\n'%(cv_mse,cv_evs,cv_r2,cv_cor))\n",
    "    out.write('Train\\t%s\\t%s\\t%s\\t%s\\n'%(train_mse,train_evs,train_r2,train_cor))\n",
    "    out.write('Test\\t%s\\t%s\\t%s\\t%s\\n'%(test_mse,test_evs,test_r2,test_cor))\n",
    "    out.write('Other_site\\t%s\\t%s\\t%s\\t%s\\n\\n'%(test_site_mse,test_site_evs,test_site_r2,test_site_cor))\n",
    "    out.close()\n",
    "    \n",
    "if y_train.shape[1] > 1:\n",
    "    perf = pd.DataFrame([cv_mse,cv_evs,cv_r2,cv_cor,train_mse,train_evs,train_r2,train_cor,\\\n",
    "                         test_mse,test_evs,test_r2,test_cor,test_site_mse,test_site_evs,\\\n",
    "                         test_site_r2,test_site_cor])\n",
    "    perf.columns = y_train.columns\n",
    "    perf.index = ['cv_mse','cv_evs','cv_r2','cv_cor','train_mse','train_evs','train_r2','train_cor',\\\n",
    "                         'test_mse','test_evs','test_r2','test_cor','test_site_mse','test_site_evs',\\\n",
    "                         'test_site_r2','test_site_cor']\n",
    "    perf.to_csv(save_performance,index=True, header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Imp_dir(X, y, imp):\n",
    "    for i in range(0,imp.shape[0]):\n",
    "        feature = imp.iloc[i,0]\n",
    "        pcc = np.corrcoef(np.array(X[feature]), np.array(y))[0,1]\n",
    "        if pcc < 0:\n",
    "            imp.iloc[i,1] = -1 * imp.iloc[i,1]\n",
    "    return (imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.shape[1] == 1:\n",
    "    imp = pd.DataFrame({'Feature':X_train_KNN.columns, 'Importance':\\\n",
    "                        grid_search.best_estimator_.feature_importances_})\n",
    "    imp_sorted = imp.sort_values(by='Importance', ascending=False)\n",
    "    imp_sorted_dir = Imp_dir(X_train_KNN, y_train, imp_sorted)\n",
    "    imp_sorted_dir.to_csv(save_imp, index=False, header=True,sep=\"\\t\")\n",
    "    \n",
    "if y_train.shape[1] > 1:\n",
    "    for i in range(0,y_train.shape[1]):\n",
    "        imp = pd.DataFrame({'Feature':X_train_KNN.columns, 'Importance_%s'%y_train.columns[i]:\\\n",
    "                        grid_search.estimators_[i].best_estimator_.feature_importances_}) \n",
    "        imp_dir = Imp_dir(X_train_KNN, y_train.iloc[:,i], imp)\n",
    "        if i == 0:\n",
    "            Imp = imp_dir\n",
    "        else:\n",
    "            Imp = pd.concat([Imp,imp_dir.iloc[:,1]],axis=1)    \n",
    "    Imp.to_csv(save_imp,index=False, header=True,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
